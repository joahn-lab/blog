---
title: "Presidential excitable speech analysis (2)"
author: "joahn"
date: '2020-06-13'
slug: presidential-excitable-speech-analysis_2
output: html_document
tags: []
categories: []
---

> 
본 프로젝트는 2회에 걸쳐 게시되었습니다. 첫 번째 게시물은 자료 수집과 전처리 및 산출식 개발 등에 초점을 맞추고, 두 번째 게시물은 본격적인 상관분석, 시각화와 주관적 분석을 다루고 있습니다.  

* * *

목차

1. 도입
    1. 간단한 소개
    2. 지난 게시물에서는
2. 상관분석 및 시각화
    1. 상관분석
    2. 시각화
        1. 단어별 시각화
        2. 부정/긍정평가 시각화
        3. 급진/중도평가 시각화
        4. 상관관계 추이 시각화
        5. 대시보드화
3. 주관적 분석

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

setwd("C:/Users/Byeongjun Cho/Documents/blog/blog/content/posts")
library(tidyverse)
library(lubridate)
library(plyr)
library(readxl)
library(writexl)
library(broom)
library(ggplot2)

Summary = read_xlsx("full.xlsx")
Summary = Summary[1:120,]
ideo = read_xlsx("poll_president_ideology.xlsx")
daily = read_xlsx("poll_president_daily.xlsx")
disaster.df = read_xlsx("Summary_df_20180206_20200529.xlsx") 
others.df = read_xlsx("others_190904_0529_but575.xlsx")
rlmeter_president = read_xlsx("poll_president.xlsx", sheet = 1, range = cell_cols("A:H"))
gallup_president = read_xlsx("poll_president.xlsx", sheet = 2, range = cell_cols("B:H"))
gallup_president = bind_cols(gallup_president[1:120,], rlmeter_president[,1]) %>% 
  select(week, everything(), -`월(M)`, -`주(W)`, -`표본 수`)

Summary.df = Summary %>%
  mutate(disaster = like_all/(like_all+dislike_all) - (like_1)/(like_1+dislike_1),
         sinner = like_all/(like_all+dislike_all) - (like_2)/(like_2+dislike_2),
         china = like_all/(like_all+dislike_all) - (like_3)/(like_3+dislike_3),
         islam = like_all/(like_all+dislike_all) - (like_4)/(like_4+dislike_4),
         head = like_all/(like_all+dislike_all) - (like_5)/(like_5+dislike_5)) %>%
  select(week, disaster, sinner, china, islam, head, everything())

Summary.df = full_join(Summary.df, rlmeter_president, by = "week") %>% 
  full_join(gallup_president, by = "week") %>%
  select(-week) %>%
  bind_cols(ideo) %>% 
  select(-week)

Summary.df = Summary.df %>%
  mutate(disaster = (like_1)/(like_1+dislike_1),
         sinner = (like_2)/(like_2+dislike_2),
         china = (like_3)/(like_3+dislike_3),
         islam = (like_4)/(like_4+dislike_4),
         head = (like_5)/(like_5+dislike_5)) %>%
  select(disaster, sinner, china, islam, head, everything())

mySumm = tibble()
for (i in colnames(Summary.df[1:5])){
  for (j in colnames(Summary.df[24:55])){
    formula = as.formula(str_c("~",i,"+",j))
    myCorr = cor.test(formula, data = Summary.df) %>% tidy()
    myCorr$word = i
    myCorr$eval = j
    mySumm = bind_rows(myCorr, mySumm)
  }
}

Summary.df.2 = Summary.df %>%
  mutate(disaster = {(like_1+dislike_1)/(like_1)}*log(num_1/num_all),
         sinner = {(like_2+dislike_2)/(like_2)}*log(num_2/num_all),
         china = {(like_3+dislike_3)/(like_3)}*log(num_3/num_all),
         islam = {(like_4+dislike_4)/(like_4)}*log(num_4/num_all),
         head = {(like_5+dislike_5)/(like_5)}*log(num_5/num_all)) %>%
  select(disaster, sinner, china, islam, head, everything())

mySumm.2 = tibble()
for (i in colnames(Summary.df.2[1:5])){
  for (j in colnames(Summary.df.2[24:55])){
    formula = as.formula(str_c("~",i,"+",j))
    myCorr = cor.test(formula, data = Summary.df.2) %>% tidy()
    myCorr$word = i
    myCorr$eval = j
    mySumm.2 = bind_rows(myCorr, mySumm.2)
  }
}
```

## 간단한 소개

<strong> 2018.2 ~ 문재인 현 대통령의 국정 지지도</strong>와 네이버/다음 메인 시사 뉴스 댓글 중 <strong>'문재앙' 키워드를 포함한 댓글의 좋아요/싫어요 수치</strong>를 구한다. 이를 상관 분석을 통해 비교하고자 한다.

## 지난 게시물에서는

지난번 게시물에서는 N2H4와 xml2, rvest 등의 패키지를 이용하여 네이버 랭킹 배너 조회수 기준 top 30개 기사에 달린 댓글 수와 좋아요/싫어요 갯수를 크롤링하고, 크롤링한 댓글 관련 데이터와 여론조사 기관의 국정 지지도 데이터를 상관분석할 수 있도록 전처리하는 작업을 서술했다. 이번에는 전처리하고 scatterplot으로 살펴본 데이터를 상관분석하고 시각화하여 이를 바탕으로 나름의 주관적 분석을 해볼까한다.

분석에 활용할 댓글 크롤링 데이터는 다음과 같다. 비하 단어 5개(순서대로 '문재앙', '문죄인', '중국몽', '문슬람', '대깨문')의 댓글 수(num_), 좋아요 수(like_), 싫어요 수(dislike_)가 순서대로 수집된 된 것을 확인할 수 있다.

```{r}
Summary
```

그리고 지난 게시물 마지막에 보았던 scatterplot을 다시 보는 것으로 시작하자.

##### Option 2는 좋아요 수 / (좋아요 + 싫어요 수)
##### Option 3는 {(좋아요 + 싫어요 수) / 좋아요 수}*log(단어 포함 댓글 수/전체 댓글 수)

```{r, echo=TRUE, eval=TRUE}
## Option 2
par(mfrow = c(2, 2))
plot(Summary.df$disaster, Summary.df.2$잘못한다, main = "문재앙 지수")
plot(Summary.df$sinner, Summary.df.2$잘못한다, main = "문죄인 지수")
plot(Summary.df$islam, Summary.df.2$잘못한다, main = "문슬람 지수")
plot(Summary.df$head, Summary.df.2$잘못한다, main = "대깨문 지수")
```
```{r, echo=TRUE, eval=TRUE}
## Option 3
par(mfrow = c(2, 2))
plot(Summary.df.2$disaster, Summary.df.2$잘못한다, main = "문재앙 지수")
plot(Summary.df.2$sinner, Summary.df.2$잘못한다, main = "문죄인 지수")
plot(Summary.df.2$islam, Summary.df.2$잘못한다, main = "문슬람 지수")
plot(Summary.df.2$head, Summary.df.2$잘못한다, main = "대깨문 지수")
```

어떤 지수를 사용할지는 우리 마음이지만, 두 개의 지수에 따른 데이터 분포는 약간 다른 형태를 보여준다. 추후 시각화된 그래프를 살펴보면 어떤 특성에 따라 다르게 나타나는지 확인할 수 있으며 이는 개별 비하 단어 사용의 특성(맥락, 어감, 비하 대상) 등의 차이를 암시한다.

## 상관분석

그렇다면 5개 단어와 여론조사 평가항목(한국갤럽 및 리얼미터) 11개 및 정치성향별(보수/진보/중도) 평가항목 21개를 합한 총 32개의 평가항목 간의 피어슨 상관계수는 어떻게 나타났을까?

```{r, echo=TRUE}
# option 2
mySumm %>% arrange(p.value) %>%
  select(word, eval, estimate, everything(), -method) %>%
  filter(p.value<.05) %>% print(n = 30)
```
```{r, echo=TRUE}
# option 3
mySumm.2 %>% arrange(p.value) %>%
  select(word, eval, estimate, everything(), -method) %>%
  filter(p.value<.05) %>% print(n = 30)
```

상관계수가 높은 상위 30개 항목을 보았을 때 상관도가 높은 단어가 지수별로 상이하게 나옴을 알 수 있다. 가령 댓글 좋아요와 싫어요를 단순 비교한 Option 2의 경우 '문재앙' 댓글이 높은 상관도를 보이는 반면, 전체 댓글 수 대비 비하 단어 포함 댓글 수를 로그 변환 후 반영하는 Option 3의 경우 '대깨문' 댓글이 높은 상관도를 보이고 있다.

이제 ggplot2 패키지를 통해 2개 지수의 상관계수를 단어별로 시각화하여 살펴보도록 하자.

### 단어별 시각화

##### Option 2
```{r cars, echo= FALSE}
mySumm %>%
  mutate(colors = ifelse(p.value<0.05, 'valid', 'invalid')) %>%
  mutate(tmp = case_when(word == "china" ~ "중국몽",
                         word == "disaster" ~ "문재앙",
                         word == "head" ~ "대깨문",
                         word == "islam" ~ "문슬람",
                         word == "sinner" ~ "문죄인")) %>%
  filter(!str_detect(eval, "보수") & !str_detect(eval, "진보") & !str_detect(eval, "중도")) %>%
  ggplot(aes(x = eval, y = estimate, fill = colors)) +
  ggtitle("비하 단어별 국정수행 평가 상관계수(A)")+
  geom_bar(stat = "identity") +
  geom_text(aes(label=round(estimate,4), vjust=-0.2), size = 2.8) +
  xlab("국정 수행 평가 항목")+
  ylab("상관계수")+
  scale_y_discrete(labels = c("중국몽", "문재앙", "대깨문", "문슬람", "문죄인"))+
  scale_fill_discrete(name = "p값(<.05) 기준 유의도", labels = c("유의하지 않다","유의하다"))+
  theme_bw()+
  coord_flip() +
  facet_wrap(~tmp)
```


##### Option 3
```{r, echo = FALSE}
mySumm.2 %>%
  mutate(colors = ifelse(p.value<0.05, 'valid', 'invalid')) %>%
  mutate(tmp = case_when(word == "china" ~ "중국몽",
                         word == "disaster" ~ "문재앙",
                         word == "head" ~ "대깨문",
                         word == "islam" ~ "문슬람",
                         word == "sinner" ~ "문죄인")) %>%
  filter(!str_detect(eval, "보수") & !str_detect(eval, "진보") & !str_detect(eval, "중도")) %>%
  ggplot(aes(x = eval, y = estimate, fill = colors)) +
  ggtitle("비하 단어별 국정수행 평가 상관계수(B)")+
  geom_bar(stat = "identity") +
  geom_text(aes(label=round(estimate,4), vjust=-0.2), size = 2.8) +
  xlab("국정 수행 평가 항목")+
  ylab("상관계수")+
  scale_y_discrete(labels = c("중국몽", "문재앙", "대깨문", "문슬람", "문죄인"))+
  scale_fill_discrete(name = "p값(<.05) 기준 유의도", labels = c("유의하지 않다","유의하다"))+
  theme_bw()+
  coord_flip() +
  facet_wrap(~tmp)
```

### 부정/긍정평가 시각화

### 급진/중도평가 시각화

### 상관관계 추이 시각화

### 샤이니 대시보드화

### 주관적 분석


<style>
body {
  font-family: NanumGothic;
  fontsize = 8px
}
</style>