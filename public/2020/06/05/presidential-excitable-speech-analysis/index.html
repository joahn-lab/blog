<!DOCTYPE html>
<html lang="">
<head>
    <meta charset="utf-8">
    
    <title>Presidential excitable speech analysis | Joahn-lab</title>
    <meta name="description" content="">
    <meta name="author" content="">
    
    <link rel="apple-touch-icon" sizes="180x180" href=/apple-touch-icon.png>
    <link rel="icon" type="image/png" sizes="32x32" href=/favicon-32x32.png>
    <link rel="icon" type="image/png" sizes="16x16" href=/favicon-16x16.png>
    <link rel="manifest" href=/site.webmanifest>
    <link rel="mask-icon" href=/safari-pinned-tab.svg color="#00416a">
    <meta name="msapplication-TileColor" content="#00aba9">
    <meta name="theme-color" content="#ffffff">
    
    
    
    
    
    
    <link rel="authorization_endpoint" href=https://indieauth.com/auth />
    <link rel="token_endpoint" href=https://tokens.indieauth.com/token />
    
    
    
    
    <link rel="stylesheet" href=/css/fonts.css />
    <link rel="stylesheet" href=/css/style.css />
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <div id="sitelogo">
        <a class="glyph" alt="Home" href="/"><img src=/images/site-logo.svg alt="Site Logo" height="64px" width="64px"></a>
    </div>
    <header>
        <nav>
    
    <div id="page-nav">
        <div class="page-nav-item">
            <a href="/">Home</a>
        </div>
        
            <div class="page-nav-item">
                <a href="/posts/">
                    
                    <span>Posts</span>
                </a>
            </div>
        
            <div class="page-nav-item">
                <a href="/about/">
                    
                    <span>About Hugo</span>
                </a>
            </div>
        
            <div class="page-nav-item">
                <a href="/about/">
                    
                    <span>About</span>
                </a>
            </div>
        
            <div class="page-nav-item">
                <a href="https://github.com/joahn-lab">
                    
                    <span>GitHub</span>
                </a>
            </div>
        
            <div class="page-nav-item">
                <a href="https://instagram.com/babyblu_deepdown">
                    
                    <span>Instagram</span>
                </a>
            </div>
        
    </div>
</nav>
        
    </header>




<div id="content">
    <article class="h-entry">
        <header>
            <h1 class="post-title p-name">Presidential excitable speech analysis</h1>
            
            <p class="post-date">Posted on
                <time class="dt-published" datetime="2020-06-05T00:00:00Z">
                    5 June, 2020 at 00:00 UTC
                </time> 
            </p>
            
            
        </header>
        <section class="content e-content">
            <pre><code class="language-{r" data-lang="{r">library(tidyverse)
library(lubridate)
library(plyr)
library(readxl)
library(writexl)
library(tictoc)
library(N2H4)
library(xml2)
library(XML)
library(rvest)

setwd(&quot;C:/Users/Byeongjun Cho/Desktop/2020-1/데이터언론학/dataset&quot;)
</code></pre><h2 id="간단한-소개">간단한 소개</h2>
<p>2018.2 ~ 문재인 현 대통령의 국정 지지도와 네이버/다음 메인 시사 뉴스 댓글 중 &lsquo;문재앙&rsquo; 키워드를 포함한 댓글의 좋아요/싫어요 수치를 구한다. 이를 상관 분석을 통해 비교하고자 한다.</p>
<h2 id="국정-지지도-자료-수집">국정 지지도 자료 수집</h2>
<p>현 대통령의 국정 지지도 수치는 국내 여론조사 기관 &lsquo;한국갤럽&rsquo;과 &lsquo;리얼미터&rsquo;의 주간 집계자료를 이용하되, 위키백과 항목에 주간별로 정리된 테이블을 스프레드시트에 옮겨 R로 전처리 후 사용한다. 보다 세부적인 대통령 국정평가 항목, 즉 &lsquo;긍정평가&rsquo; &lsquo;부정평가&rsquo; 수치는 각 여론조사 기관 홈페이지에 게재되는 주간 동향 보도자료 내 수치를 스프레드시트로 정리한 후 사용한다.
cf. 구글 스프레드시트를 통해 크롤링하는 방법도 고려했지만, 여론조사 홈페이지 URL 링크의 불규칙성, 한글 주소의 인코딩 문제, PDF 파일 크롤링의 어려움 등을 감안해 주간 자료를 직접 table로 정리하는 것이 효율적이라고 판단했다.</p>
<p>국정 지지도 자료를 구하는 데에는 크게 2가지 경로가 있다. 하나는 위키백과 &lsquo;대통령 지지율&rsquo; 항목에서 표로 정리된 리얼미터/한국갤럽 자료를 이용하는 것이고, 다른 하나는 해당 조사기관 홈페이지에 주마다 게시되는 보도자료를 직접 참조하는 것이다. 나는 일차적인 분석을 위해 간편한 위키백과 도표 자료를 이용하고, 일정한 인사이트를 얻은 후 해당 홈페이지에 게시된 보도자료의 더 상세한 수치를 직접 정리하여 R로 불러왔다.</p>
<pre><code class="language-{r" data-lang="{r">
# 조사기관 보도자료 내 긍정/부정평가 항목 데이터 불러오기 (리얼미터, 한국갤럽)

rlmeter_president = read_xlsx(&quot;poll_president.xlsx&quot;, sheet = 1, range = cell_cols(&quot;A:H&quot;))
gallup_president = read_xlsx(&quot;poll_president.xlsx&quot;, sheet = 2, range = cell_cols(&quot;B:H&quot;))
gallup_president = bind_cols(gallup_president[1:120,], rlmeter_president[,1]) %&gt;% 
  select(...1, everything(), -`월(M)`, -`주(W)`, -`표본 수`)

# 위키백과 '대통령 지지도' 항목에서 긁어온 데이터 전처리

wiki = read_xlsx(&quot;wiki_president.xlsx&quot;)

for (i in 39:71){
  wiki[i-1, 1:3] = wiki[i,1:3]}
for (i in 73:160){
  wiki[i-2, 1:3] = wiki[i,1:3]}

wiki = wiki[1:158, 1:3]
wiki = wiki %&gt;% mutate(gallup = as.character(`한국갤럽[3]`),
                gallup = ifelse(gallup == &quot;미조사&quot;, NA, round(as.numeric(gallup),3)),
                rlmeter = as.character(`리얼미터[4]`),
                rlmeter = ifelse(rlmeter == &quot;미조사&quot;, NA, round(as.numeric(rlmeter),3)))
wiki$gallup = round(as.numeric(wiki$gallup), 4)
wiki$rlmeter = round(as.numeric(wiki$rlmeter), 5)
</code></pre><h2 id="문재앙-지수-만들기-1-댓글-크롤링">문재앙 지수 만들기 (1) 댓글 크롤링</h2>
<h2 id="네이버-기사-링크-추출">네이버 기사 링크 추출</h2>
<p>댓글을 크롤링할 기사로 뉴스 랭킹 배너에 조회수 기준 일간 상위 30개의 기사(부문별 5개, 총 6개 부문)을 선정한다.</p>
<p>네이버 &lsquo;많이 본 기사&rsquo; 랭킹 배너 링크를 들어가보면,
(&ldquo;<a href="https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&amp;date=20180212%22)(2018.2.12">https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&amp;date=20180212&quot;)(2018.2.12</a>일자)
일간 누적 집계된 조회수 기준 상위 30개의 6개 부문 기사 제목과 링크가 나열되어 있는 것을 확인할 수 있다.
우리는 여기서 구글 스프레드 시트의 importxml() 함수와 xpath 정규 표현식을 활용하여 일자별 30개의 기사 링크를 긁어올 수 있다.
여기서 랭킹 배너의 링크에는 일정한 규칙성이 있으므로, 랭킹 배너에 접근할 URL은 main_url(&ldquo;<a href="https://news.naver.com">https://news.naver.com</a>&rdquo;)에 sub_url 변수를 for문을 통해 조합하는 방식으로 마련하였다.
조사 대상 날짜인 2018.02.06 ~ 2020.06. ** 에서 일자별 자동 추출된 30개의 기사링크는 구글 스프레드시트에 쌓고 &ldquo;naver_df.xlsx&rdquo; 파일로 추출한 후 이를 R로 불러온다.</p>
<p>+) 위와 같이 기사 링크를 추출하는 방식은 importxml() 함수를 사용하기 위해 구글 스프레드시트를 거쳐야 하는 불편함이 다소 있었다. 따라서 &lsquo;다음&rsquo; 기사 링크를 추출할 때는 Rstudio 내에서 해당 크롤링 작업을 할 수 있도록 하였다. 즉, &lsquo;xml2&rsquo; 패키지의 read_html() 함수와 &lsquo;rvest&rsquo; 패키지의 html_nodes() 함수 등을 이용하여 랭킹 배너의 html 소스코드에 열거된 상위 10개 기사의 링크를 가져오도록 했다. (하단 코드 참조)</p>
<h2 id="댓글-필터링-및-크롤링-좋아요싫어요-수-합산">댓글 필터링 및 크롤링, 좋아요/싫어요 수 합산</h2>
<p>크롤링할 댓글 양이 상당하다는 점을 감안해 이미 마련된 패키지를 활용하기로 한다. 사용할 패키지는 N2H4, DNH4이며,
각각 네이버/다음 내부 기사 URL을 인자로 넣으면 해당 기사에 달린 댓글과 좋아요/싫어요 수 등 다양한 변수를 크롤링해준다. 현재까지 문재앙 지수를 산출하는 데 필요한 변수들은 다음과 같다.</p>
<ol>
<li>일간 상위 30개 기사에 달린 모든 댓글의 좋아요/싫어요 총합</li>
<li>&lsquo;문재앙&rsquo; 및 관련 어휘가 포함/제외된 모든 댓글의 좋아요/싫어요 총합</li>
<li>&lsquo;문재앙&rsquo; 및 관련 어휘가 포함/제외된 모든 댓글 수</li>
</ol>
<p>그런데 이때, 우리는 타당한 지수 산출을 위해 매크로 및 유령 계정 활용, &lsquo;좌표 찍기&rsquo;를 비롯한 댓글상의 정치 공작 등의 불필요한 과도표집을 예방해야 할 것이다. 따라서 특정 댓글 내용을 아예 똑같이 복사한 경우인 기사 내/(동일 일자) 기사 간 중복댓글을 표본에서 배제하고, 중복댓글 중 시간상 마지막에 달린 단 1개의 댓글만을 표본에 반영할 것이다. 또한 &lsquo;문재앙&rsquo; 어휘를 포함한 임의의 1000개 댓글을 훑어본 결과,  100개당 1-2개꼴로 현 대통령을 지지하는 댓글을 발견했는데, 대체로 &lsquo;문재앙 타령&rsquo; 이라고 말하는 식이었다. 따라서 &lsquo;문재앙&rsquo;이라는 어휘가 포함된 댓글 중 &lsquo;타령&rsquo;이라는 어휘가 없거나, &lsquo;탄핵&rsquo;이라는 강한 부정어를 포함하는 댓글을 수집하는 것으로 2차 필터링을 거쳤다.</p>
<pre><code class="language-{r" data-lang="{r">
main_url = &quot;https://news.naver.com&quot;
operator = &quot;/main/ranking/popularDay.nhn?rankingType=popular_day&amp;date=&quot;
datelist = read_xlsx(&quot;datelist.xlsx&quot;, range = cell_cols(&quot;B&quot;)) %&gt;% as_tibble()

Summary_3 = tibble()
for (j in 1:nrow(datelist)){
  Summary_1 = tibble()
  Summary_2 = tibble()
  tmp_1 = tibble()
  tmp_2 = tibble()
  date = datelist[j,1]
  doc = read_html(str_c(main_url, operator, date))
  tmp = html_nodes(doc, 'dl') %&gt;% html_nodes('a') %&gt;% html_attr(&quot;href&quot;)
  tic()
  for (i in 1:30){
    sub_url = tmp[i]
    tmp_1 = getAllComment(str_c(main_url, sub_url)) %&gt;%
      as_tibble() %&gt;%
      filter(!duplicated(contents)) %&gt;%
      select(contents, ends_with(&quot;Count&quot;), -imageCount)
    Summary_1 = bind_rows(Summary_1, tmp_1)
    
    tmp_2 = tmp_1 %&gt;%
      filter(str_detect(contents, &quot;문재앙&quot;)) %&gt;%
      filter(!str_detect(contents, &quot;타령&quot;)) %&gt;%
      select(contents, ends_with(&quot;Count&quot;))
    Summary_2 = bind_rows(Summary_2, tmp_2)}
  toc()
  
  nrow = nrow(Summary_1)
  nrow_1 = nrow(Summary_2)
  Summary_1 = Summary_1 %&gt;%
    filter(!duplicated(contents))
  like = sum(Summary_1$sympathyCount)
  dislike = sum(Summary_1$antipathyCount)
  
  Summary_2 = Summary_2 %&gt;%
    filter(!duplicated(contents))
  like_1 = sum(Summary_2$sympathyCount)
  dislike_1 = sum(Summary_2$antipathyCount)

  Summary_3[j, 1] = ymd(date)
  Summary_3[j, 2] = like
  Summary_3[j, 3] = dislike
  Summary_3[j, 4] = nrow
  Summary_3[j, 5] = like_1
  Summary_3[j, 6] = dislike_1
  Summary_3[j, 7] = nrow_1

  print(ymd(date))}

write.csv(Summary_3, &quot;Summary_df_5.csv&quot;)

Summary_3$week = as.Date(cut(Summary_3$...1, breaks = &quot;week&quot;, start.on.monday = FALSE)) - 1
Summary_3
for (i in 2:767){
  Summary_3$week[i-1] = Summary_3$week[i]}
</code></pre><h2 id="다음-기사-링크-추출">다음 기사 링크 추출</h2>
<p>&lsquo;다음&rsquo;의 경우 랭킹 뉴스 배너 조회수 기준 일자별 상위 10개 기사를 댓글 추출 대상으로 한다. (&lsquo;2019 언론수용자 조사&rsquo;의 포털별 뉴스 점유율에 따라(네이버 91%, 다음 20%, 중복응답) 기사 갯수를 선정했다.) 크롤링 코드는 다음과 같다. 앞서 언급한대로 &lsquo;xml2&rsquo;, &lsquo;rvest&rsquo; 패키지 내장 함수를 통해 html 소스코드에서 일자별 기사 링크를 추출하고 해당 링크 기사에 달린 댓글들에 접근하는 방식을 취하였다. 이떄 사용한 &lsquo;DNH4&rsquo; 패키지의 getAllComment() 함수는 패키지상의 오류가 발생하곤 했으므로 상응하는 예외처리를 거쳤다.</p>
<pre><code class="language-{r" data-lang="{r">library(DNH4)

main_url = &quot;https://media.daum.net/ranking/popular&quot;
operator = &quot;?regDate=&quot;
datelist = read_xlsx(&quot;datelist.xlsx&quot;, range = cell_cols(&quot;B&quot;)) %&gt;% as_tibble()
linklist = list()

Summary_4 = tibble()
print(datelist, n = 300)

for (i in 1:nrow(datelist)){
  Summary_1 = tibble()
  Summary_2 = tibble()
  date = datelist[i,1] 

  doc = read_html(str_c(main_url, operator, date))
  tmp = html_nodes(doc, 'li') %&gt;% html_nodes('a') %&gt;% html_attr(&quot;href&quot;)
  linklist = unique(tmp[44:63])

for (j in 1:length(linklist)){
  tic()
  tmp_1 = tibble()
  tmp_2 = tibble()
    sub_url = linklist[j]
    if(is_null(tryNULL(getAllComment(sub_url)))){next} else {
    tmp_1 = getAllComment(sub_url) %&gt;% as.data.table() %&gt;%
      as_tibble() %&gt;%
      filter(!duplicated(content)) %&gt;%
      select(content, likeCount, dislikeCount)
    Summary_1 = bind_rows(Summary_1, tmp_1)
    
    tmp_2 = tmp_1 %&gt;%
      filter(str_detect(content, &quot;문재앙&quot;)) %&gt;%
      filter(!str_detect(content, &quot;타령&quot;)) %&gt;%
      select(content, likeCount, dislikeCount)
    Summary_2 = bind_rows(Summary_2, tmp_2)}}
  toc()
  
  Summary_1 = Summary_1 %&gt;%
    filter(!duplicated(content))
  nrow = nrow(Summary_1)
  like = sum(Summary_1$likeCount)
  dislike = sum(Summary_1$dislikeCount)
  
  Summary_2 = Summary_2 %&gt;%
    filter(!duplicated(content))
  nrow_1 = nrow(Summary_2)
  like_1 = sum(Summary_2$likeCount)
  dislike_1 = sum(Summary_2$dislikeCount)
  
  Summary_4[i-1, 1] = date
  Summary_4[i-1, 2] = like
  Summary_4[i-1, 3] = dislike
  Summary_4[i-1, 4] = nrow
  Summary_4[i-1, 5] = like_1
  Summary_4[i-1, 6] = dislike_1
  Summary_4[i-1, 7] = nrow_1
  print(i)}

write.csv(Summary_4, &quot;Summary_new_df_daum.csv&quot;)
</code></pre><p>&lsquo;문재앙&rsquo; 어휘를 포함한 댓글이 수집된 Summary_2 데이터를 살펴보자. (예외처리를 거친) 대략 845일간의 &lsquo;문재앙&rsquo; 댓글 전량을 수집하였음에도 4500개 댓글뿐으로, 이는 하루 5개 정도의 댓글만이 &lsquo;문재앙&rsquo; 어휘를 사용했음을 뜻한다. 다음 플랫폼 주 이용자의 정치적 성향을 고려하더라도 이는 상당히 적은 양의 댓글 수이므로 독립적인 표본으로서 결과에 반영하기 애매한듯 보이므로 우선은 분석 대상에서 제외하는 것이 나을 것 같다.</p>
<h2 id="문재앙-지수-만들기-2-국정-지지도와-초벌-상관-분석">문재앙 지수 만들기 (2) 국정 지지도와 초벌 상관 분석</h2>
<p>이제 수집된 네이버 댓글 데이터와 위키백과의 &lsquo;대통령 지지도&rsquo; 항목에 제시된 국정평가 도표 수치를 비교해보자. 대강의 상관관계를 파악하는 데 도움을 줄 것이다.</p>
<pre><code class="language-{r" data-lang="{r">#계산법 yes/yes+no - like/like+dislike 하고 -1은 완전 긍정평가 1은 완전 부정평가로 간주
Summary_3 = Summary_3 %&gt;%
  group_by(week) %&gt;%
  mutate(disaster = ...1/(...2 + ...1) - ...4/(...4+...5))
Summary_3 = Summary_3 %&gt;% mutate(tmp_total = ...1/(...2 + ...1)) %&gt;% mutate(tmp_mun = ...4/(...4+...5))
cor.test(Summary_3$tmp_total, Summary_3$tmp_mun) # 상관계수 0.2228306 약한 양적 선형 관계

Summary_5 = tibble()
for (i in 1:111){
Summary_5[i,1] = mean(Summary_3$disaster[Summary_3$week == unique(Summary_3$week)[i]])}
print(wiki, n = Inf)

wiki = wiki %&gt;% mutate(gallup = ifelse(is.na(gallup), rlmeter, gallup)) %&gt;% mutate(rlmeter = ifelse(is.na(rlmeter), gallup, rlmeter))

for (i in 39:149){
Summary_5[i-38,2] = mean(wiki$gallup[i], wiki$rlmeter[i], na.rm = TRUE)}
# 56행은 18년 6월 1주, 두 여론조사 기관 모두 미조사므로 뺴고 계산
Summary_5 = Summary_5[c(1:~~, ~~:111),]

cor.test(Summary_5$...1, Summary_5$...2) # 두 계수가 관련 있을 수도 있다! 피어슨 상관계수 0.6468249

# 우선 여기까지 저장
write_xlsx(Summary_3, &quot;disaster_df.xlsx&quot;)
write_xlsx(Summary_4, &quot;compare_ratio_df.xlsx&quot;)
</code></pre><h2 id="문재앙-지수-만들기-3-인사이트-파악-후-산출식-수정">문재앙 지수 만들기 (3) 인사이트 파악 후 산출식 수정</h2>
<p>여기서 나아가 다른 어휘들은 어떤 상관관계가 있을지까지 파악해 보기로 했다. 코드는 다음과 같다.
(네이버 서버상의 문제인지 같은 일자에서 계속해서 오류가 발생했다. 따라서 for문을 돌리는 와중에 중간중간 오류 발생 시 예외처리를 하고 코드 실행을 재개해야 한다.)</p>
<pre><code class="language-{r" data-lang="{r">main_url = &quot;https://news.naver.com&quot;
operator = &quot;/main/ranking/popularDay.nhn?rankingType=popular_day&amp;date=&quot;
datelist = read_xlsx(&quot;datelist.xlsx&quot;, range = cell_cols(&quot;B&quot;)) %&gt;% as_tibble()
# datelist = datelist[774:844, 1]

Summary_3 = tibble()

for (j in 1:nrow(datelist)){
  Summary_2 = tibble()
  Summary_4 = tibble()
  Summary_5 = tibble()
  Summary_6 = tibble()
  date = datelist[j,1]
  doc = read_html(str_c(main_url, operator, date))
  tmp = html_nodes(doc, 'dl') %&gt;% html_nodes('a') %&gt;% html_attr(&quot;href&quot;)
  tic()
  tmp_1 = tibble()
  tmp_2 = tibble()
  tmp_3 = tibble()
  tmp_4 = tibble()
  tmp_5 = tibble()
  for (i in 1:30){
    sub_url = tmp[i]
    tmp_1 = getAllComment(str_c(main_url, sub_url)) %&gt;%
      as_tibble() %&gt;%
      filter(!duplicated(contents)) %&gt;%
      select(contents, ends_with(&quot;Count&quot;), -imageCount)
    
    tmp_2 = tmp_1 %&gt;%
      filter(str_detect(contents, &quot;문죄인&quot;)) %&gt;%
      filter(!str_detect(contents, &quot;일베&quot;)) %&gt;%
      filter(!str_detect(contents, &quot;타령&quot;)) %&gt;%
      select(contents, ends_with(&quot;Count&quot;))
    Summary_2 = bind_rows(Summary_2, tmp_2)
    
    tmp_3 = tmp_1 %&gt;%
      filter(str_detect(contents, &quot;중국몽&quot;)) %&gt;%
      filter(!str_detect(contents, &quot;일베&quot;)) %&gt;%
      filter(!str_detect(contents, &quot;타령&quot;)) %&gt;%
      select(contents, ends_with(&quot;Count&quot;))
    Summary_4 = bind_rows(Summary_4, tmp_3)
    
    tmp_4 = tmp_1 %&gt;%
      filter(str_detect(contents, &quot;문슬람&quot;)) %&gt;%
      filter(!str_detect(contents, &quot;일베&quot;)) %&gt;%
      filter(!str_detect(contents, &quot;타령&quot;)) %&gt;%
      select(contents, ends_with(&quot;Count&quot;))
    Summary_5 = bind_rows(Summary_5, tmp_4)
    
    tmp_5 = tmp_1 %&gt;%
      filter(str_detect(contents, &quot;대깨문&quot;)) %&gt;%
      filter(!str_detect(contents, &quot;일베&quot;)) %&gt;%
      filter(!str_detect(contents, &quot;타령&quot;)) %&gt;%
      select(contents, ends_with(&quot;Count&quot;))
    Summary_6 = bind_rows(Summary_6, tmp_5)}
  toc()
  
  Summary_2 = Summary_2 %&gt;%
    filter(!duplicated(contents))
  Summary_4 = Summary_4 %&gt;%
    filter(!duplicated(contents))
  Summary_5 = Summary_5 %&gt;%
    filter(!duplicated(contents))
  Summary_6 = Summary_6 %&gt;%
    filter(!duplicated(contents))
  
  nrow_1 = nrow(Summary_2)
  nrow_2 = nrow(Summary_4)
  nrow_3 = nrow(Summary_5)
  nrow_4 = nrow(Summary_6)

  like_1 = sum(Summary_2$sympathyCount)
  dislike_1 = sum(Summary_2$antipathyCount)
  like_2 = sum(Summary_4$sympathyCount)
  dislike_2 = sum(Summary_4$antipathyCount)
  like_3 = sum(Summary_5$sympathyCount)
  dislike_3 = sum(Summary_5$antipathyCount)
  like_4 = sum(Summary_6$sympathyCount)
  dislike_4 = sum(Summary_6$antipathyCount)
  
  Summary_3[j, 1] = ymd(date)
  Summary_3[j, 2] = like_1
  Summary_3[j, 3] = dislike_1
  Summary_3[j, 4] = nrow_1
  Summary_3[j, 5] = like_2
  Summary_3[j, 6] = dislike_2
  Summary_3[j, 7] = nrow_2
  Summary_3[j, 8] = like_3
  Summary_3[j, 9] = dislike_3
  Summary_3[j, 10] = nrow_3
  Summary_3[j, 11] = like_4
  Summary_3[j, 12] = dislike_4
  Summary_3[j, 13] = nrow_4
        
  print(ymd(date))}

write.csv(Summary_3, &quot;others_190904_0529_but575.csv&quot;)

Summary_3$week = as.Date(cut(as.Date(Summary_3$...7), breaks = &quot;week&quot;, start.on.monday = FALSE)) - 1
for (i in 2:838){
  Summary_3$week[i-1] = Summary_3$week[i]}

Summary_full = tibble()
for (i in 1:121){
  Summary_full[i,1] = sum(Summary_3$...2[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,2] = sum(Summary_3$...3[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,3] = sum(Summary_3$...4[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,4] = sum(Summary_3$...5[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,5] = sum(Summary_3$...6[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,6] = sum(Summary_3$...7[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,7] = sum(Summary_3$...8[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,8] = sum(Summary_3$...9[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,9] = sum(Summary_3$...10[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,10] = sum(Summary_3$...11[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,11] = sum(Summary_3$...12[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,12] = sum(Summary_3$...13[Summary_3$week == unique(Summary_3$week)[i]])
  Summary_full[i,13] = unique(Summary_3$week)[i]}

write_xlsx(Summary_full, &quot;full.xlsx&quot;)
</code></pre><p>엑셀 스프레드시트로 변수명 변경 및 열 배치 등 간단한 전처리를 하고 여론조사 집계자료와 상관분석할 준비를 마친다.</p>
<h2 id="문재앙-지수-분석하기">문재앙 지수 분석하기</h2>

        </section>
        <footer>
            <a class="permalink u-url" href="/2020/06/05/presidential-excitable-speech-analysis/"></a>
            
        </footer>
    </article>
</div>

    
    <div id="footer">
      
      <nav id="article-skip">
        <div class="next">
          
          <a alt="Newer article" href="/about/">&larr; Newer</a>
          
        </div>
        <div class="top">
          <a alt="Top of page" href="#">Top</a>
        </div>
        <div class="prev">
          
          <a alt="Older article" href="/posts/presidential-excitable-speech-analysis_1/">Older &rarr;</a>
          
        </div>
      </nav>
      
      <aside id="social">
  <div id="social-icons">
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  </div>
</aside>

      
      <p class="copyright">
          Copyright &amp;copy; 2019 - Author Name
      </p>
      
    </div>


</body>
</html>